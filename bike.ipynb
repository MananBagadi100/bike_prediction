{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ignore Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "#reading the dataset\n",
    "dataset=pd.read_csv('day.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assign string values\n",
    "#1 is spring, 2 is summer, 3 is fall, 4 is winter\n",
    "dataset.loc[(dataset['season']==1),'season']='spring'\n",
    "dataset.loc[(dataset['season']==2),'season']='summar'\n",
    "dataset.loc[(dataset['season']==3),'season']='fall'\n",
    "dataset.loc[(dataset['season']==4),'season']='winter'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['season'].astype('category').value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#0 is 2018 and 1 is 2019\n",
    "dataset['yr'].astype('category').value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function to map numeric month values to string month names\n",
    "def object_map_mnths(x):\n",
    "    return x.map({\n",
    "        1: 'Jan', 2: 'Feb', 3: 'Mar', 4: 'Apr', 5: 'May', \n",
    "        6: 'Jun', 7: 'Jul', 8: 'Aug', 9: 'Sept', 10: 'Oct', \n",
    "        11: 'Nov', 12: 'Dec'\n",
    "    })\n",
    "\n",
    "# Applying the mapping function to the 'mnth' column\n",
    "dataset[['mnth']] = dataset[['mnth']].apply(object_map_mnths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['mnth'].astype('category').value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['holiday'].astype('category').value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function to map numeric weekday values to string weekday names\n",
    "def str_map_weekday(x):\n",
    "    return x.map({\n",
    "        1: 'Mon', 2: 'Tues', 3: 'Wed', 4: 'Thurs', \n",
    "        5: 'Fri', 6: 'Sat', 0: 'Sun'\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Applying the mapping function to the 'weekday' column\n",
    "dataset[['weekday']] = dataset[['weekday']].apply(str_map_weekday)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[['weekday']].astype('category').value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[['workingday']].astype('category').value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning string values to different weather conditions\n",
    "# 1 = Clear, few clouds, partly cloudy\n",
    "dataset.loc[dataset['weathersit'] == 1, 'weathersit'] = 'A'\n",
    "\n",
    "# 2 = Mist, Cloudy\n",
    "dataset.loc[dataset['weathersit'] == 2, 'weathersit'] = 'B'\n",
    "\n",
    "# 3 = Light Snow, Heavy Rain\n",
    "dataset.loc[dataset['weathersit'] == 3, 'weathersit'] = 'C'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Changing the 'weathersit' column type to category and counting the occurrences of each category\n",
    "dataset['weathersit'] = dataset['weathersit'].astype('category')\n",
    "dataset['weathersit'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(dataset['temp'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#actual temparature\n",
    "sns.distplot(dataset['atemp'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wind speed\n",
    "sns.distplot(dataset['windspeed'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#target variable : total count of rental bikes including both casual and registered\n",
    "sns.distplot(dataset['cnt'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the 'dteday' column to datetime format with specific precision\n",
    "dataset['dteday'] = dataset['dteday'].astype('datetime64[ns]')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Selecting only categorical columns, excluding specific data types\n",
    "dataset_categorical = dataset.select_dtypes(exclude=['float64', 'datetime64', 'int64'])\n",
    "dataset_categorical.drop('weathersit',axis=1,inplace=True)\n",
    "# Displaying the categorical columns (though this line is incomplete in the image)\n",
    "print(dataset_categorical.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,20))\n",
    "plt.subplot(3,3,1)\n",
    "sns.boxplot(x = 'season' , y = 'cnt', data=dataset)\n",
    "plt.subplot(3,3,2)\n",
    "sns.boxplot(x = 'mnth' , y = 'cnt', data=dataset)\n",
    "plt.subplot(3,3,3)\n",
    "sns.boxplot(x = 'weekday' , y = 'cnt', data=dataset)\n",
    "plt.subplot(3,3,4)\n",
    "sns.boxplot(x = 'weathersit' , y = 'cnt', data=dataset)\n",
    "plt.subplot(3,3,5)\n",
    "sns.boxplot(x = 'workingday' , y = 'cnt', data=dataset)\n",
    "plt.subplot(3,3,6)\n",
    "sns.boxplot(x = 'yr' , y = 'cnt', data=dataset)\n",
    "plt.subplot(3,3,7)\n",
    "sns.boxplot(x = 'holiday' , y = 'cnt', data=dataset)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of integer variables to be converted to float\n",
    "intVarlist = [\"casual\", \"registered\", \"cnt\"]\n",
    "\n",
    "# Converting the specified columns to float data type\n",
    "for var in intVarlist:\n",
    "    dataset[var] = dataset[var].astype(\"float\")\n",
    "\n",
    "# Selecting only the numeric columns (float64) and displaying the first few rows\n",
    "dataset_numeric = dataset.select_dtypes(include=['float64'])\n",
    "dataset_numeric.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(dataset_numeric)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cor=dataset_numeric.corr()\n",
    "cor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a mask for the upper triangle of the heatmap\n",
    "mask = np.array(cor)\n",
    "mask[np.tril_indices_from(mask)] = False\n",
    "\n",
    "# Setting up the figure and axis for the plot\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(10, 10)\n",
    "\n",
    "# Creating the heatmap with a mask, setting vmax and enabling annotations\n",
    "sns.heatmap(cor, mask=mask, vmax=1, square=True, annot=True)\n",
    "\n",
    "# Displaying the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.drop('atemp',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting only categorical columns (object dtype)\n",
    "dataset_categorical = dataset.select_dtypes(include=['object'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying the first few rows of the categorical dataset\n",
    "dataset_categorical.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Converting categorical variables into dummy/indicator variables\n",
    "dataset_dummies = pd.get_dummies(dataset_categorical, drop_first=True)\n",
    "\n",
    "# Ensure that the boolean values are converted to integers (0 and 1)\n",
    "dataset_dummies = dataset_dummies.astype(int)\n",
    "\n",
    "# Displaying the first few rows of the dataset with dummy variables\n",
    "dataset_dummies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=dataset.drop(list(dataset_categorical.columns),axis=1)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=pd.concat([dataset,dataset_dummies],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=dataset.drop(['instant','dteday'],axis=1,inplace=False)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries for linear regression\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Splitting the dataset into train and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Setting a random seed for reproducibility\n",
    "np.random.seed(0)\n",
    "\n",
    "# Splitting the dataset: 70% training, 30% testing\n",
    "df_train, df_test = train_test_split(dataset, train_size=0.7, test_size=0.3, random_state=100)\n",
    "\n",
    "# Displaying the training set\n",
    "df_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing MinMaxScaler from sklearn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Initializing the MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# List of columns to apply scaling to (excluding dummy variables)\n",
    "var = [\"temp\", \"hum\", \"windspeed\", \"casual\", \"registered\", \"cnt\"]\n",
    "\n",
    "# Applying the scaler to the selected columns in the training set\n",
    "df_train[var] = scaler.fit_transform(df_train[var])\n",
    "\n",
    "# Displaying summary statistics of the training data\n",
    "df_train.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclude non-numeric columns from df_train before calculating correlation\n",
    "df_train_numeric = df_train.select_dtypes(include=[np.number])\n",
    "\n",
    "# Checking the correlation coefficients to see which variables are highly correlated\n",
    "plt.figure(figsize=(30, 30))\n",
    "sns.heatmap(df_train_numeric.corr(), annot=True, cmap=\"YlGnBu\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 782,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividing the data into X (features) and y (target)\n",
    "x_train = df_train.drop([\"casual\", \"registered\"], axis=1)\n",
    "y_train = df_train.pop('cnt')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Displaying the first few rows of the X_train dataset\n",
    "x_train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Converting X_train to a NumPy array\n",
    "np.array(df_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test\n",
    "df_train.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 786,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train = pd.get_dummies(x_train, columns=['weathersit'], drop_first=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "x_train_lm = sm.add_constant(x_train)\n",
    "lr = sm.OLS(y_train, x_train_lm).fit()\n",
    "print(lr.params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm=LinearRegression()\n",
    "lm.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lm.coef_)\n",
    "print(lm.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import RFE\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Create a linear regression model\n",
    "lm = LinearRegression()\n",
    "\n",
    "# Initialize RFE with 15 features\n",
    "rfe1 = RFE(lm, 15)\n",
    "\n",
    "# Fit RFE with the training data\n",
    "rfe1.fit(x_train, y_train)\n",
    "\n",
    "# Print the support (True/False for selected features) and ranking\n",
    "print(rfe1.support_)\n",
    "print(rfe1.ranking_)\n",
    "\n",
    "# Get the names of the selected features\n",
    "col1 = x_train.columns[rfe1.support_]\n",
    "print(col1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import variance inflation factor\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# Dropping constant column (if present)\n",
    "a = x_train_rfe1.drop('const', axis=1)\n",
    "\n",
    "# Evaluating VIFs\n",
    "vif = pd.DataFrame()\n",
    "vif['features'] = a.columns\n",
    "vif['VIF'] = [variance_inflation_factor(a.values, i) for i in range(a.shape[1])]\n",
    "vif['VIF'] = round(vif['VIF'], 2)\n",
    "\n",
    "# Sorting the VIF values in descending order\n",
    "vif = vif.sort_values(by='VIF', ascending=False)\n",
    "\n",
    "# Displaying the VIF DataFrame\n",
    "vif\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform RFE with 7 features\n",
    "lm = LinearRegression()\n",
    "rfe2 = RFE(lm, 7)\n",
    "\n",
    "# Fit RFE with training data\n",
    "rfe2.fit(x_train, y_train)\n",
    "print(rfe2.support_)\n",
    "print(rfe2.ranking_)\n",
    "\n",
    "# Get selected feature columns\n",
    "col2 = x_train.columns[rfe2.support_]\n",
    "\n",
    "# Select the chosen features\n",
    "x_train_rfe2 = x_train[col2]\n",
    "\n",
    "# Add a constant and fit an OLS model\n",
    "import statsmodels.api as sm\n",
    "x_train_rfe2 = sm.add_constant(x_train_rfe2)\n",
    "lm2 = sm.OLS(y_train, x_train_rfe2).fit()\n",
    "\n",
    "# Display the summary of the OLS regression results\n",
    "lm2.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping constant column (if present)\n",
    "b = x_train_rfe2.drop('const', axis=1)\n",
    "\n",
    "# Calculating VIF for each feature\n",
    "vif1 = pd.DataFrame()\n",
    "vif1['features'] = b.columns\n",
    "vif1['VIF'] = [variance_inflation_factor(b.values, i) for i in range(b.shape[1])]\n",
    "vif1['VIF'] = round(vif1['VIF'], 2)\n",
    "\n",
    "# Sorting VIF values in descending order\n",
    "vif1 = vif1.sort_values(by='VIF', ascending=False)\n",
    "\n",
    "# Displaying the VIF DataFrame\n",
    "vif1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting using the OLS model\n",
    "y_train_cnt = lm2.predict(x_train_rfe2)\n",
    "\n",
    "# Plotting the distribution of predictions\n",
    "fig = plt.figure()\n",
    "sns.distplot((y_train, y_train_cnt), bins=20)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming test data using the same scaler\n",
    "df_test[var] = scaler.transform(df_test[var])\n",
    "df_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating the target variable and dropping unnecessary columns\n",
    "y_test = df_test.pop('cnt')\n",
    "x_test = df_test.drop([\"casual\", \"registered\"], axis=1)\n",
    "\n",
    "# Displaying the first few rows of x_test\n",
    "x_test.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the constant from training data\n",
    "c = x_train_rfe2.drop('const', axis=1)\n",
    "\n",
    "# Extracting the column names from the training data\n",
    "col2 = c.columns\n",
    "\n",
    "# Selecting the same features from the test data\n",
    "x_test_rfe2 = x_test[col2]\n",
    "\n",
    "# Adding a constant to the test data\n",
    "x_test_rfe2 = sm.add_constant(x_test_rfe2)\n",
    "\n",
    "# Displaying the structure of the test data\n",
    "x_test_rfe2.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting on the test data\n",
    "y_pred = lm2.predict(x_test_rfe2)\n",
    "\n",
    "# Plotting the predicted vs actual values\n",
    "plt.figure()\n",
    "plt.scatter(y_test, y_pred)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the R-squared metric and calculating R-squared\n",
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting a heatmap of the correlation matrix for the selected features\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.heatmap(dataset[col2].corr(), cmap=\"YlGnBu\", annot=True)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ve",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
